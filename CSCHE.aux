\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Masliyah2004}
\citation{Fong2004}
\citation{ZhangANN}
\citation{MichalewiczGP}
\citation{brunet2004metagenes,devarajan2008nonnegative,KozaGP}
\citation{berry2005email}
\citation{BurkardtImageGA,zafeiriou2006exploiting,kotsia2007novel}
\citation{weninger2012optimization}
\citation{HouckGA}
\citation{ding2010convex}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\citation{MichalewiczGP}
\citation{SchmidtSR}
\citation{Tsoumakas2007}
\@writefile{toc}{\contentsline {section}{\numberline {2}Methodology}{2}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Symbolic Regression via Genetic Programming}{2}{subsection.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Genetic Programming(GP) iteration procedure: The tree-based GP iteration controls the evolved SR generation and destruct the unpromising offspring.\relax }}{2}{figure.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:GP_procedure.png}{{1}{2}{Genetic Programming(GP) iteration procedure: The tree-based GP iteration controls the evolved SR generation and destruct the unpromising offspring.\relax }{figure.caption.1}{}}
\citation{richard2010AD}
\citation{baresel2002fitness}
\citation{baresel2002fitness}
\citation{VladislavlevaSR}
\citation{VladislavlevaSR}
\citation{ding2010convex}
\citation{ding2010convex}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Fitness Prediction and Constraint Optimization}{3}{subsection.2.2}}
\newlabel{eq:optimization_function}{{1}{3}{Fitness Prediction and Constraint Optimization}{equation.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The execution of the first individual (covering the six nodes 1, 3, 4, 5, 7, and 8 on the target path) will lead to a high approximation level if all identical path sections are considered for the fitness evaluation. If only the first matching path section is measured, the second individual (covering five nodes 1, 2, 3, 4, and 7) will lead to a higher approximation level than the first one\cite  {baresel2002fitness}\relax }}{3}{figure.caption.2}}
\newlabel{fig:learning_path.png}{{2}{3}{The execution of the first individual (covering the six nodes 1, 3, 4, 5, 7, and 8 on the target path) will lead to a high approximation level if all identical path sections are considered for the fitness evaluation. If only the first matching path section is measured, the second individual (covering five nodes 1, 2, 3, 4, and 7) will lead to a higher approximation level than the first one\cite {baresel2002fitness}\relax }{figure.caption.2}{}}
\newlabel{eq:function_derivative}{{2}{3}{Fitness Prediction and Constraint Optimization}{equation.2.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Implementation Procedure}{3}{section.3}}
\newlabel{sec:experiments}{{3}{3}{Implementation Procedure}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Problem Setup}{3}{subsection.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Table 1. Comparison of SR with three other modeling techniques (Linear Regression, Neural Networks and Random Forests) which belong to three distinct culture in modeling prediction family\cite  {VladislavlevaSR}\relax }}{4}{figure.caption.3}}
\newlabel{Table:SR_comparison}{{\caption@xref {Table:SR_comparison}{ on input line 480}}{4}{Fitness Prediction and Constraint Optimization}{figure.caption.3}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces This proposed algorithm for training a SR model: Initially we approximate the factors greedily using the automatic differentiation algorithm \cite  {ding2010convex} and then fine-tune the factors until the convergence criterion is satisfied.\relax }}{4}{algorithm.1}}
\newlabel{algo:deepnmfalgo}{{1}{4}{This proposed algorithm for training a SR model: Initially we approximate the factors greedily using the automatic differentiation algorithm \cite {ding2010convex} and then fine-tune the factors until the convergence criterion is satisfied.\relax }{algorithm.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Implementation Details}{4}{subsection.3.2}}
\newlabel{tab:iteration}{{\caption@xref {tab:iteration}{ on input line 645}}{5}{Implementation Details}{table.caption.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Table 2. Results of fitness function generation, for a variable number of combinations of input attributes from the simulation data.\relax }}{5}{table.caption.4}}
\@writefile{toc}{\contentsline {section}{\numberline {4}SR descriptor results}{5}{section.4}}
\newlabel{sec:related}{{4}{5}{SR descriptor results}{section.4}{}}
\newlabel{eq:deep_nmf_linear_cost}{{7}{6}{SR descriptor results}{equation.4.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Symbolic regression prediction of the relationship between recovery and temperature.\relax }}{6}{figure.caption.5}}
\newlabel{fig:T_SR}{{4}{6}{Symbolic regression prediction of the relationship between recovery and temperature.\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Symbolic regression prediction of the relationship between recovery and pH.\relax }}{6}{figure.caption.6}}
\newlabel{fig:pH_SR}{{5}{6}{Symbolic regression prediction of the relationship between recovery and pH.\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Symbolic regression prediction of the relationship between recovery and Cf.\relax }}{7}{figure.caption.7}}
\newlabel{fig:CF_SR}{{6}{7}{Symbolic regression prediction of the relationship between recovery and Cf.\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Symbolic regression prediction of the relationship between recovery and temperature. Blue hollow square indicate actual data points. By altering clay fines amount to 30\%, red solid curve is visualized compared with original dark solid curve.\relax }}{7}{figure.caption.8}}
\newlabel{fig:t_comparison.png}{{7}{7}{Symbolic regression prediction of the relationship between recovery and temperature. Blue hollow square indicate actual data points. By altering clay fines amount to 30\%, red solid curve is visualized compared with original dark solid curve.\relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Symbolic regression prediction of the relationship between recovery and pH. Blue hollow square indicate actual data points. The difference between red and dark visualized curves is 10 degree alteration of temperature.\relax }}{7}{figure.caption.9}}
\newlabel{fig:ph_comparison.png}{{8}{7}{Symbolic regression prediction of the relationship between recovery and pH. Blue hollow square indicate actual data points. The difference between red and dark visualized curves is 10 degree alteration of temperature.\relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Symbolic regression prediction of the relationship between recovery and clay fines. Blue hollow square indicate actual data points. The difference between red and dark visualized curves is 5 degree alteration of temperature. \relax }}{7}{figure.caption.10}}
\newlabel{fig:Cf_comparison.png}{{9}{7}{Symbolic regression prediction of the relationship between recovery and clay fines. Blue hollow square indicate actual data points. The difference between red and dark visualized curves is 5 degree alteration of temperature. \relax }{figure.caption.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{7}{section.5}}
\newlabel{sec:conclusion}{{5}{7}{Conclusion}{section.5}{}}
\bibstyle{IEEEtran}
\bibcite{Masliyah2004}{1}
\bibcite{Fong2004}{2}
\bibcite{ZhangANN}{3}
\bibcite{MichalewiczGP}{4}
\bibcite{brunet2004metagenes}{5}
\bibcite{devarajan2008nonnegative}{6}
\bibcite{KozaGP}{7}
\bibcite{berry2005email}{8}
\bibcite{BurkardtImageGA}{9}
\bibcite{zafeiriou2006exploiting}{10}
\bibcite{kotsia2007novel}{11}
\bibcite{weninger2012optimization}{12}
\bibcite{HouckGA}{13}
\bibcite{ding2010convex}{14}
\bibcite{SchmidtSR}{15}
\bibcite{Tsoumakas2007}{16}
\bibcite{Herrero2001}{17}
\bibcite{VladislavlevaSR}{18}
\bibcite{baresel2002fitness}{19}
\bibcite{richard2010AD}{20}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Symbolic regression model performance.\relax }}{8}{figure.caption.11}}
\newlabel{fig:sensitivity.eps}{{10}{8}{Symbolic regression model performance.\relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Symbolic regression prediction performance.\relax }}{8}{figure.caption.12}}
\newlabel{fig:sensitivity2.eps}{{11}{8}{Symbolic regression prediction performance.\relax }{figure.caption.12}{}}
\@writefile{toc}{\contentsline {section}{References}{8}{section*.13}}
